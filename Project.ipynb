{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Activation, ZeroPadding2D, Add, Concatenate\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'celeba-dataset/img_align_celeba'\n",
    "attributes_path = 'celeba-dataset/list_attr_celeba.csv'\n",
    "image_folder = 'categories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load attribute data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair',\n",
       "       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee',\n",
       "       'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male',\n",
       "       'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
       "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
       "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair',\n",
       "       'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
       "       'Wearing_Necklace', 'Wearing_Necktie', 'Young'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_df = pd.read_csv(attributes_path)\n",
    "attributes_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_keep = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male']\n",
    "attribute_data = attributes_df[attributes_to_keep]\n",
    "attribute_data = attribute_data.values # note that index starts with 0 and image id with 1!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define networks:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "epochs = 10\n",
    "save_interval = 1\n",
    "batch_size = 512\n",
    "#batches_per_epoch = train_generator.n // batch_size\n",
    "train_generator= None\n",
    "data_generator = None\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "batches_per_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "nbr_of_features = 5\n",
    "in_features = Input(shape=[nbr_of_features])\n",
    "noise_input = Input(shape=[noise_size])\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    generator_input = Concatenate()([noise_input, in_features])\n",
    "    #generator_input = Input(shape=[latent_dim + nbr_input_features])\n",
    "    fc = Dense(128*8*8)(generator_input)\n",
    "    #fc = Dense(16*16*3, activation='sigmoid')(generator_input)\n",
    "    fc = LeakyReLU(alpha=0.2)(fc)\n",
    "    image = Reshape((8,8,128))(fc)\n",
    "    \n",
    "    image = UpSampling2D()(image) # 16\n",
    "    image = Conv2D(128, kernel_size=3, padding=\"same\")(image)\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image = UpSampling2D()(image) # 32\n",
    "    image = Conv2D(64, kernel_size=3, padding=\"same\")(image)\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image = UpSampling2D()(image) # 64\n",
    "    image = Conv2D(32, kernel_size=3, padding=\"same\")(image)\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    #image = UpSampling2D()(image) # 128\n",
    "    image = Conv2D(3, kernel_size=3, padding=\"same\", activation='sigmoid')(image)\n",
    "    \n",
    "    return Model([noise_input, in_features], image)\n",
    "\n",
    "def build_discriminator():\n",
    "    \n",
    "    image_input = Input(shape=(64,64,3))\n",
    "    \n",
    "    image = Conv2D(32, kernel_size=5, padding=\"same\", strides=2)(image_input) # 32\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image = Dropout(0.25)(image)\n",
    "    image = Conv2D(64, kernel_size=5, padding=\"same\", strides=2)(image) # 16\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image = Dropout(0.25)(image)\n",
    "    image = Conv2D(128, kernel_size=5, padding=\"same\", strides=2)(image)# 8\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image = Dropout(0.25)(image)\n",
    "    image = Conv2D(256, kernel_size=5, padding=\"same\", strides=1)(image) # 8\n",
    "    image = BatchNormalization()(image)\n",
    "    image = LeakyReLU(alpha=0.2)(image)\n",
    "    \n",
    "    image_flat = Flatten()(image)\n",
    "    \n",
    "    classifier_input = Concatenate()([image_flat, in_features])\n",
    "    \n",
    "    fc_size = 64\n",
    "    hidden = Dense(fc_size)(classifier_input)\n",
    "    hidden = LeakyReLU(alpha=0.2)(hidden)\n",
    "    out = Dense(1, activation='sigmoid')(hidden)\n",
    "    \n",
    "    return Model([image_input, in_features], out)\n",
    "#discriminator = Model([in_image, in_features], discriminator_classifier([current_discriminator_cnn(in_image), in_features]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d_loss_hist, g_loss_hist):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(d_loss_hist, label='Discriminator')\n",
    "    plt.plot(g_loss_hist, label='Generator')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Loss over epochs')\n",
    "    \n",
    "feature_matrix = attribute_data[0:25,:]\n",
    "\n",
    "def numpy_rescaled(x):\n",
    "    out = x.copy()\n",
    "    out[x<0] = 0\n",
    "    out[x>1] = 1\n",
    "    return out\n",
    "\n",
    "def save_imgs(epoch, generator):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, noise_size))\n",
    "    gen_imgs = generator.predict([noise, feature_matrix])\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/celebA_%d.png\" % epoch)\n",
    "    plt.close()\n",
    "\n",
    "def train_gan(discriminator, generator, combined_model, epochs=10, batches_per_epoch=None):\n",
    "    if batches_per_epoch is None:\n",
    "        batches_per_epoch = train_generator.n // batch_size\n",
    "\n",
    "\n",
    "    d_loss_hist = list()\n",
    "    g_loss_hist = list()\n",
    "    for epoch in range(epochs):\n",
    "       \n",
    "        for i_batch in range(batches_per_epoch):\n",
    "        # Select a random batch of images\n",
    "            imgs, y = train_generator.next()\n",
    "            # one hot to feature\n",
    "            y = np.argmax(y, axis = 1)\n",
    "            input_features = attribute_data[y, :]\n",
    "            \n",
    "            b_size = imgs.shape[0]\n",
    "            valid = np.ones((b_size, 1))\n",
    "            fake = np.zeros((b_size, 1))\n",
    "\n",
    "            if i_batch%40 == 0:\n",
    "                print('Currently on batch: %d for epoch: %d' % (i_batch, epoch))\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (b_size, noise_size))\n",
    "            # Generator features\n",
    "            \n",
    "            gen_imgs = generator.predict([noise, input_features])\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = discriminator.train_on_batch([imgs, input_features], valid)\n",
    "            d_loss_fake = discriminator.train_on_batch([gen_imgs, input_features], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = combined_model.train_on_batch([noise, input_features], valid)\n",
    "\n",
    "        d_loss_hist.append(d_loss[0])\n",
    "        g_loss_hist.append(g_loss)\n",
    "        # Plot the progress\n",
    "        print (\"epoch: %d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(epoch, generator)\n",
    "    \n",
    "    return d_loss_hist, g_loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "# First generator step\n",
    "generator = build_generator()\n",
    "#current_generator_model.summary()\n",
    "\n",
    "# First Discriminator step, only classifier\n",
    "discriminator = build_discriminator()\n",
    "#discriminator_classifier.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Train step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_size = (64, 64)\n",
    "#input_shape = (target_size[0], target_size[1], 3)\n",
    "\n",
    "def get_data_generators(image_size):\n",
    "    data_generator = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "    train_generator = data_generator.flow_from_directory(image_folder, \n",
    "                                                         target_size=(image_size, image_size), \n",
    "                                                         batch_size=batch_size)\n",
    "    return data_generator, train_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# The generator takes noise as input and generates imgs\n",
    "img = generator([noise_input, in_features])\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator([img, in_features])\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model([noise_input, in_features], valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 202599 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator, train_generator = get_data_generators(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on batch: 0 for epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [D loss: 0.751595, acc.: 46.48%] [G loss: 1.573588]\n",
      "Currently on batch: 0 for epoch: 1\n",
      "epoch: 1 [D loss: 1.041518, acc.: 35.06%] [G loss: 1.728811]\n",
      "Currently on batch: 0 for epoch: 2\n",
      "epoch: 2 [D loss: 0.876887, acc.: 36.52%] [G loss: 1.258386]\n",
      "Currently on batch: 0 for epoch: 3\n",
      "epoch: 3 [D loss: 1.009390, acc.: 31.45%] [G loss: 1.496295]\n",
      "Currently on batch: 0 for epoch: 4\n",
      "epoch: 4 [D loss: 0.600527, acc.: 69.73%] [G loss: 0.972666]\n",
      "Currently on batch: 0 for epoch: 5\n",
      "epoch: 5 [D loss: 0.724693, acc.: 56.35%] [G loss: 0.763243]\n",
      "Currently on batch: 0 for epoch: 6\n",
      "epoch: 6 [D loss: 0.043730, acc.: 99.61%] [G loss: 0.020152]\n",
      "Currently on batch: 0 for epoch: 7\n",
      "epoch: 7 [D loss: 0.008725, acc.: 100.00%] [G loss: 0.005374]\n",
      "Currently on batch: 0 for epoch: 8\n",
      "epoch: 8 [D loss: 0.009546, acc.: 100.00%] [G loss: 0.007216]\n",
      "Currently on batch: 0 for epoch: 9\n",
      "epoch: 9 [D loss: 0.010880, acc.: 100.00%] [G loss: 0.006306]\n"
     ]
    }
   ],
   "source": [
    "d_loss_hist, g_loss_hist = train_gan(discriminator, generator, combined, epochs=epochs, batches_per_epoch=batches_per_epoch)\n",
    "plot_history(d_loss_hist, g_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the models from step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
